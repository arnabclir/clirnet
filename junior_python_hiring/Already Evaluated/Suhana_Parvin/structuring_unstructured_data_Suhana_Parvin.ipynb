{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Structuring Unstructured Data with LLMs - DSPy Practical\n",
        "# Suhana Parvin\n",
        "# ========================================================="
      ],
      "metadata": {
        "id": "GyJbHg3LTjMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 1. Install required packages\n",
        "# -----------------------------\n",
        "!pip install dspy-ai trafilatura pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lrqtxUDTZYI",
        "outputId": "62ebef4c-d3da-40d0-c5af-160703237884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dspy-ai in /usr/local/lib/python3.12/dist-packages (3.0.4)\n",
            "Requirement already satisfied: trafilatura in /usr/local/lib/python3.12/dist-packages (2.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: dspy>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from dspy-ai) (3.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from trafilatura) (2025.11.12)\n",
            "Requirement already satisfied: charset_normalizer>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (3.4.4)\n",
            "Requirement already satisfied: courlan>=1.3.2 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (1.3.2)\n",
            "Requirement already satisfied: htmldate>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (1.9.4)\n",
            "Requirement already satisfied: justext>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (3.0.2)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (6.0.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (2.5.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: babel>=2.16.0 in /usr/local/lib/python3.12/dist-packages (from courlan>=1.3.2->trafilatura) (2.17.0)\n",
            "Requirement already satisfied: tld>=0.13 in /usr/local/lib/python3.12/dist-packages (from courlan>=1.3.2->trafilatura) (0.13.1)\n",
            "Requirement already satisfied: backoff>=2.2 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.2.1)\n",
            "Requirement already satisfied: joblib~=1.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (1.5.2)\n",
            "Requirement already satisfied: openai>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.9.0)\n",
            "Requirement already satisfied: regex>=2023.10.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2025.11.3)\n",
            "Requirement already satisfied: orjson>=3.9.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.11.4)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (4.67.1)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.32.4)\n",
            "Requirement already satisfied: optuna>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (4.6.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.12.3)\n",
            "Requirement already satisfied: magicattr>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (0.1.6)\n",
            "Requirement already satisfied: litellm>=1.64.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (1.80.9)\n",
            "Requirement already satisfied: diskcache>=5.6.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (5.6.3)\n",
            "Requirement already satisfied: json-repair>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (0.54.2)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (9.1.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (4.12.0)\n",
            "Requirement already satisfied: asyncer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (0.0.8)\n",
            "Requirement already satisfied: cachetools>=5.5.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (6.2.2)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.1.2)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (13.9.4)\n",
            "Requirement already satisfied: pillow>=10.1.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (11.3.0)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.6.0)\n",
            "Requirement already satisfied: gepa==0.0.17 in /usr/local/lib/python3.12/dist-packages (from gepa[dspy]==0.0.17->dspy>=3.0.4->dspy-ai) (0.0.17)\n",
            "Requirement already satisfied: dateparser>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from htmldate>=1.9.2->trafilatura) (1.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio->dspy>=3.0.4->dspy-ai) (3.11)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->dspy>=3.0.4->dspy-ai) (4.15.0)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.12/dist-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (5.3.1)\n",
            "Requirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.13.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (8.3.1)\n",
            "Requirement already satisfied: fastuuid>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.14.0)\n",
            "Requirement already satisfied: grpcio<1.68.0,>=1.62.3 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.67.1)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (4.25.1)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.2.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.12.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.22.1)\n",
            "Requirement already satisfied: lxml_html_clean in /usr/local/lib/python3.12/dist-packages (from lxml[html_clean]>=4.4.2->justext>=3.0.1->trafilatura) (0.4.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=0.28.1->dspy>=3.0.4->dspy-ai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai>=0.28.1->dspy>=3.0.4->dspy-ai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=0.28.1->dspy>=3.0.4->dspy-ai) (1.3.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (1.17.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (6.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (2.0.44)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (6.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.4->dspy-ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.4->dspy-ai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.4->dspy-ai) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->dspy>=3.0.4->dspy-ai) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->dspy>=3.0.4->dspy-ai) (2.19.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.22.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (1.3.10)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.30.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy>=3.0.4->dspy-ai) (0.1.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (3.3.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 2. Imports\n",
        "# -----------------------------\n",
        "import dspy\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "import trafilatura\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "NbD9SahjRgrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 3. Configure LLM\n",
        "# -----------------------------\n",
        "API_KEY = \"ak_15Y8kS6dp2Iy8Lt0Tl2Ip5Oz3ap6a\"  # Replace with your LongCat API key\n",
        "main_lm = dspy.LM(\"openai/LongCat-Flash-Chat\", api_key=API_KEY, api_base=\"https://api.longcat.chat/openai/v1\")\n",
        "dspy.settings.configure(lm=main_lm, adapter=dspy.XMLAdapter())"
      ],
      "metadata": {
        "id": "grm0MiWzSK6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 4. Entity Extraction Classes\n",
        "# -----------------------------\n",
        "class EntityWithAttr(BaseModel):\n",
        "    entity: str = Field(description=\"the named entity\")\n",
        "    attr_type: str = Field(description=\"semantic type of the entity (e.g. Crop, Process, Concept)\")\n",
        "\n",
        "class ExtractEntities(dspy.Signature):\n",
        "    paragraph: str = dspy.InputField(desc=\"input paragraph\")\n",
        "    entities: List[EntityWithAttr] = dspy.OutputField(desc=\"list of entities and their attribute types\")\n",
        "\n",
        "extractor = dspy.Predict(ExtractEntities)"
      ],
      "metadata": {
        "id": "h3g6B3ZLS3Ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 5. Deduplication Classes\n",
        "# -----------------------------\n",
        "class DeduplicateEntities(dspy.Signature):\n",
        "    items: List[EntityWithAttr] = dspy.InputField(desc=\"batch of entities to deduplicate\")\n",
        "    deduplicated: List[EntityWithAttr] = dspy.OutputField(desc=\"deduplicated list\")\n",
        "    confidence: float = dspy.OutputField(desc=\"confidence that all items are distinct\")\n",
        "\n",
        "dedup_predictor = dspy.ChainOfThought(DeduplicateEntities)\n",
        "\n",
        "def deduplicate_with_lm(items: List[EntityWithAttr], batch_size: int = 10, target_confidence: float = 0.9) -> List[EntityWithAttr]:\n",
        "    if not items:\n",
        "        return []\n",
        "\n",
        "    def _process_batch(batch: List[EntityWithAttr]) -> List[EntityWithAttr]:\n",
        "        while True:\n",
        "            pred = dedup_predictor(items=batch)\n",
        "            if pred.confidence >= target_confidence:\n",
        "                return pred.deduplicated\n",
        "\n",
        "    results = []\n",
        "    for i in range(0, len(items), batch_size):\n",
        "        batch = items[i:i+batch_size]\n",
        "        results.extend(_process_batch(batch))\n",
        "    return results"
      ],
      "metadata": {
        "id": "MdDUEW1zS7Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 6. Relation Extraction Classes\n",
        "# -----------------------------\n",
        "class Relation(BaseModel):\n",
        "    subj: str = Field(description=\"subject entity (exact string from deduplicated list)\")\n",
        "    pred: str = Field(description=\"short predicate / relation phrase\")\n",
        "    obj: str = Field(description=\"object entity (exact string from deduplicated list)\")\n",
        "\n",
        "class ExtractRelations(dspy.Signature):\n",
        "    paragraph: str = dspy.InputField(desc=\"original paragraph\")\n",
        "    entities: List[str] = dspy.InputField(desc=\"deduplicated entities\")\n",
        "    relations: List[Relation] = dspy.OutputField(desc=\"list of subject-predicate-object triples\")\n",
        "\n",
        "rel_predictor = dspy.ChainOfThought(ExtractRelations)"
      ],
      "metadata": {
        "id": "w0i5OW3OTBGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 7. Mermaid Diagram Function\n",
        "# -----------------------------\n",
        "def triples_to_mermaid(triples: List[Relation], entity_list: List[str], max_label_len: int = 40) -> str:\n",
        "    entity_set = {e.strip().lower() for e in entity_list}\n",
        "    lines = [\"flowchart LR\"]\n",
        "\n",
        "    def _make_id(s: str) -> str:\n",
        "        return s.strip().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"-\", \"_\")\n",
        "\n",
        "    for t in triples:\n",
        "        subj_norm, obj_norm = t.subj.strip().lower(), t.obj.strip().lower()\n",
        "\n",
        "        if obj_norm in entity_set:\n",
        "            src, dst, lbl = t.subj, t.obj, t.pred\n",
        "        elif subj_norm in entity_set:\n",
        "            src, dst, lbl = t.obj, t.subj, t.pred\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        lbl = lbl.strip()\n",
        "        if len(lbl) > max_label_len:\n",
        "            lbl = lbl[:max_label_len-3] + \"...\"\n",
        "\n",
        "        src_id, dst_id = _make_id(src), _make_id(dst)\n",
        "        lines.append(f'    {src_id}[\"{src}\"] -->|{lbl}| {dst_id}[\"{dst}\"]')\n",
        "\n",
        "    return \"\\n\".join(lines)"
      ],
      "metadata": {
        "id": "xTCU9Q89TB2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 8. URLs to Scrape\n",
        "# -----------------------------\n",
        "URLS = [\n",
        "    \"https://en.wikipedia.org/wiki/Sustainable_agriculture\",\n",
        "    \"https://www.nature.com/articles/d41586-025-03353-5\",\n",
        "    \"https://www.sciencedirect.com/science/article/pii/S1043661820315152\",\n",
        "    \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10457221/\",\n",
        "    \"https://www.fao.org/3/y4671e/y4671e06.htm\",\n",
        "    \"https://www.medscape.com/viewarticle/time-reconsider-tramadol-chronic-pain-2025a1000ria\",\n",
        "    \"https://www.sciencedirect.com/science/article/pii/S0378378220307088\",\n",
        "    \"https://www.frontiersin.org/news/2025/09/01/rectangle-telescope-finding-habitable-planets\",\n",
        "    \"https://www.medscape.com/viewarticle/second-dose-boosts-shingles-protection-adults-aged-65-years-2025a1000ro7\",\n",
        "    \"https://www.theguardian.com/global-development/2025/oct/13/astro-ambassadors-stargazers-himalayas-hanle-ladakh-india\"\n",
        "]\n",
        "\n",
        "os.makedirs(\"mermaid_outputs\", exist_ok=True)\n",
        "rows = []"
      ],
      "metadata": {
        "id": "3U9_a521SRrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 9. Scrape & Process Each URL\n",
        "# -----------------------------\n",
        "for idx, url in enumerate(URLS, start=1):\n",
        "    print(f\"\\n============================\")\n",
        "    print(f\"PROCESSING URL {idx}: {url}\")\n",
        "    print(\"============================\")\n",
        "\n",
        "    downloaded = trafilatura.fetch_url(url)\n",
        "    text = trafilatura.extract(downloaded)\n",
        "\n",
        "    if not text:\n",
        "        print(\"Could not extract text. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # 1. Entity extraction\n",
        "    extracted = extractor(paragraph=text)\n",
        "    entities = extracted.entities\n",
        "\n",
        "    # 2. Deduplication\n",
        "    unique = deduplicate_with_lm(entities)\n",
        "\n",
        "    # 3. Relation extraction\n",
        "    entity_strings = [e.entity for e in unique]\n",
        "    rel_out = rel_predictor(paragraph=text, entities=entity_strings)\n",
        "\n",
        "    # 4. Mermaid generation\n",
        "    mermaid_code = triples_to_mermaid(rel_out.relations, entity_strings)\n",
        "\n",
        "    # Save Mermaid file\n",
        "    md_path = f\"mermaid_outputs/mermaid_{idx}.md\"\n",
        "    with open(md_path, \"w\") as f:\n",
        "        f.write(\"```mermaid\\n\")\n",
        "        f.write(mermaid_code)\n",
        "        f.write(\"\\n```\")\n",
        "    print(f\"Saved Mermaid diagram to {md_path}\")\n",
        "\n",
        "    # Add CSV rows\n",
        "    for e in unique:\n",
        "        rows.append({\n",
        "            \"link\": url,\n",
        "            \"tag\": e.entity,\n",
        "            \"tag_type\": e.attr_type\n",
        "        })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4v9UR69SX3d",
        "outputId": "efd1c2a4-336a-431d-e9a1-6b042b001f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================\n",
            "PROCESSING URL 1: https://en.wikipedia.org/wiki/Sustainable_agriculture\n",
            "============================\n",
            "Saved Mermaid diagram to mermaid_outputs/mermaid_1.md\n",
            "\n",
            "============================\n",
            "PROCESSING URL 2: https://www.nature.com/articles/d41586-025-03353-5\n",
            "============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:trafilatura.downloads:download error: https://www.nature.com/articles/d41586-025-03353-5 HTTPSConnectionPool(host='idp.nature.com', port=443): Max retries exceeded with url: https://idp.nature.com/transit?redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fd41586-025-03353-5&code=e8e5d42e-29f8-4485-aa54-fe1b8a34bbc1 (Caused by ResponseError('too many redirects'))\n",
            "WARNING:trafilatura.core:discarding data: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not extract text. Skipping.\n",
            "\n",
            "============================\n",
            "PROCESSING URL 3: https://www.sciencedirect.com/science/article/pii/S1043661820315152\n",
            "============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:trafilatura.downloads:not a 200 response: 403 for URL https://www.sciencedirect.com/science/article/pii/S1043661820315152\n",
            "WARNING:trafilatura.core:discarding data: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not extract text. Skipping.\n",
            "\n",
            "============================\n",
            "PROCESSING URL 4: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10457221/\n",
            "============================\n",
            "Saved Mermaid diagram to mermaid_outputs/mermaid_4.md\n",
            "\n",
            "============================\n",
            "PROCESSING URL 5: https://www.fao.org/3/y4671e/y4671e06.htm\n",
            "============================\n",
            "Saved Mermaid diagram to mermaid_outputs/mermaid_5.md\n",
            "\n",
            "============================\n",
            "PROCESSING URL 6: https://www.medscape.com/viewarticle/time-reconsider-tramadol-chronic-pain-2025a1000ria\n",
            "============================\n",
            "Saved Mermaid diagram to mermaid_outputs/mermaid_6.md\n",
            "\n",
            "============================\n",
            "PROCESSING URL 7: https://www.sciencedirect.com/science/article/pii/S0378378220307088\n",
            "============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:trafilatura.downloads:not a 200 response: 403 for URL https://www.sciencedirect.com/science/article/pii/S0378378220307088\n",
            "WARNING:trafilatura.core:discarding data: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not extract text. Skipping.\n",
            "\n",
            "============================\n",
            "PROCESSING URL 8: https://www.frontiersin.org/news/2025/09/01/rectangle-telescope-finding-habitable-planets\n",
            "============================\n",
            "Saved Mermaid diagram to mermaid_outputs/mermaid_8.md\n",
            "\n",
            "============================\n",
            "PROCESSING URL 9: https://www.medscape.com/viewarticle/second-dose-boosts-shingles-protection-adults-aged-65-years-2025a1000ro7\n",
            "============================\n",
            "Saved Mermaid diagram to mermaid_outputs/mermaid_9.md\n",
            "\n",
            "============================\n",
            "PROCESSING URL 10: https://www.theguardian.com/global-development/2025/oct/13/astro-ambassadors-stargazers-himalayas-hanle-ladakh-india\n",
            "============================\n",
            "Saved Mermaid diagram to mermaid_outputs/mermaid_10.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 10. Save Structured CSV\n",
        "# -----------------------------\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv(\"tags.csv\", index=False)\n",
        "print(\"\\nAll done! CSV saved as tags.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG1hDTmmTP5v",
        "outputId": "c5c53253-0c22-49d0-f3a3-bd4f1eadb034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "All done! CSV saved as tags.csv\n"
          ]
        }
      ]
    }
  ]
}