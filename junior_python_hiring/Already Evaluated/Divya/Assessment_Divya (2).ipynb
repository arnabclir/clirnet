{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4ca670fda0e34989a25417042897a7bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c50352356ec743b2ab165dd9923d1dee",
              "IPY_MODEL_3e902e3574c3451882c5d1b0ed1432a0",
              "IPY_MODEL_31cecd66f5614561b675d1504625d96b"
            ],
            "layout": "IPY_MODEL_4c33241109a34d8bb9a70acf57354c69"
          }
        },
        "c50352356ec743b2ab165dd9923d1dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ca908163d2f4f1aa18500d2d349e2cf",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_86909d9f8bab41849aac75c4584dcae4",
            "value": "Overallâ€‡Progress:â€‡100%"
          }
        },
        "3e902e3574c3451882c5d1b0ed1432a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27b5882e6ace417f85a81d06249ecf75",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15c538e34b5f46db8c0514b69e06cf5f",
            "value": 10
          }
        },
        "31cecd66f5614561b675d1504625d96b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d40a7c893426477d9d2cbcac8d0058bf",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c5d14e2dfff145309e467ef7d3db7f4f",
            "value": "â€‡10/10â€‡[00:32&lt;00:00,â€‡â€‡2.52s/it]"
          }
        },
        "4c33241109a34d8bb9a70acf57354c69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ca908163d2f4f1aa18500d2d349e2cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86909d9f8bab41849aac75c4584dcae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27b5882e6ace417f85a81d06249ecf75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15c538e34b5f46db8c0514b69e06cf5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d40a7c893426477d9d2cbcac8d0058bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5d14e2dfff145309e467ef7d3db7f4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXgWzckxaU3R"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Install Dependencies\n",
        "# ----------------------------------------------------------------------------\n",
        "!pip install -q dspy-ai beautifulsoup4 requests tqdm pandas pydantic\n",
        "\n",
        "# Note: If prompted to restart runtime after dspy-ai installation, do so before continuing\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Import Required Libraries\n",
        "# ----------------------------------------------------------------------------\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "import json\n",
        "from typing import List, Set, Tuple\n",
        "from pathlib import Path\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "\n",
        "# DSPy and Pydantic imports\n",
        "import dspy\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "print(\"âœ“ All libraries imported successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-1jVuMoaZ1K",
        "outputId": "acd185be-9dab-4469-f1ed-cf65a4f82654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ All libraries imported successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Configuration & Setup\n",
        "# ----------------------------------------------------------------------------\n",
        "# IMPORTANT: Add your LongCat API key here\n",
        "API_KEY = \"\"  # <-- PASTE YOUR API KEY HERE\n",
        "\n",
        "if not API_KEY:\n",
        "    raise ValueError(\" API_KEY is empty! Please add your LongCat API key in Cell 3\")\n",
        "\n",
        "# Configure DSPy with LongCat API\n",
        "lm = dspy.LM(\n",
        "    model=\"openai/LongCat-Flash-Chat\",\n",
        "    api_key=API_KEY,\n",
        "    api_base=\"https://api.longcat.chat/openai/v1\"\n",
        ")\n",
        "dspy.configure(lm=lm, adapter=dspy.XMLAdapter())\n",
        "\n",
        "print(\"âœ“ DSPy configured with LongCat API\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hARzGmDfafyg",
        "outputId": "d7ceaac6-48f9-4573-b1ba-d1e751f1c792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ DSPy configured with LongCat API\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Define Pydantic Models & DSPy Signatures\n",
        "# ----------------------------------------------------------------------------\n",
        "# These enforce structured outputs from the LLM (no regex parsing needed!)\n",
        "\n",
        "class EntityWithAttr(BaseModel):\n",
        "    \"\"\"Represents a named entity with its semantic type\"\"\"\n",
        "    entity: str = Field(description=\"The named entity extracted from text\")\n",
        "    attr_type: str = Field(description=\"Semantic type (e.g., Crop, Process, Disease, Technology)\")\n",
        "\n",
        "class ExtractEntities(dspy.Signature):\n",
        "    \"\"\"Extract named entities and their types from a paragraph\"\"\"\n",
        "    paragraph: str = dspy.InputField(desc=\"Input text to analyze\")\n",
        "    entities: List[EntityWithAttr] = dspy.OutputField(desc=\"List of extracted entities with types\")\n",
        "\n",
        "class DeduplicateEntities(dspy.Signature):\n",
        "    \"\"\"Deduplicate similar entities using semantic understanding\"\"\"\n",
        "    items: List[EntityWithAttr] = dspy.InputField(desc=\"List of entities to deduplicate\")\n",
        "    deduplicated: List[EntityWithAttr] = dspy.OutputField(desc=\"Deduplicated entity list\")\n",
        "    confidence: float = dspy.OutputField(desc=\"Confidence score (0-1) for deduplication quality\")\n",
        "\n",
        "class Relation(BaseModel):\n",
        "    \"\"\"Represents a knowledge graph triple (subject-predicate-object)\"\"\"\n",
        "    subj: str = Field(description=\"Subject entity\")\n",
        "    pred: str = Field(description=\"Relationship/predicate\")\n",
        "    obj: str = Field(description=\"Object entity\")\n",
        "\n",
        "class ExtractRelations(dspy.Signature):\n",
        "    \"\"\"Extract semantic relationships between entities\"\"\"\n",
        "    paragraph: str = dspy.InputField(desc=\"Source text\")\n",
        "    entities: List[str] = dspy.InputField(desc=\"List of validated entity names\")\n",
        "    relations: List[Relation] = dspy.OutputField(desc=\"Extracted subject-predicate-object triples\")\n",
        "\n",
        "# Initialize predictors\n",
        "extractor = dspy.Predict(ExtractEntities)\n",
        "dedup_predictor = dspy.ChainOfThought(DeduplicateEntities)\n",
        "rel_predictor = dspy.ChainOfThought(ExtractRelations)\n",
        "\n",
        "print(\"âœ“ DSPy signatures and predictors initialized\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUYONgZMamm3",
        "outputId": "8d5ab1f3-93cc-4921-fabb-754bb23bd4f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ DSPy signatures and predictors initialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Core Pipeline Functions\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "def scrape_text_from_url(url: str, timeout: int = 20) -> str:\n",
        "    \"\"\"\n",
        "    Scrape main text content from a URL with robust error handling\n",
        "\n",
        "    Args:\n",
        "        url: Target URL to scrape\n",
        "        timeout: Request timeout in seconds\n",
        "\n",
        "    Returns:\n",
        "        Cleaned text content or empty string on failure\n",
        "    \"\"\"\n",
        "    try:\n",
        "        headers = {\n",
        "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n",
        "        }\n",
        "        response = requests.get(url, timeout=timeout, headers=headers)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "        # Remove non-content elements\n",
        "        for element in soup([\"script\", \"style\", \"noscript\", \"header\", \"footer\", \"nav\"]):\n",
        "            element.decompose()\n",
        "\n",
        "        # Extract text from content-rich tags\n",
        "        content_tags = soup.find_all([\"p\", \"h1\", \"h2\", \"h3\", \"h4\", \"li\", \"article\", \"section\"])\n",
        "        text_blocks = [tag.get_text(separator=\" \", strip=True) for tag in content_tags]\n",
        "\n",
        "        # Join and clean\n",
        "        full_text = \"\\n\".join(text_blocks)\n",
        "        # Remove excessive whitespace\n",
        "        full_text = re.sub(r'\\s+', ' ', full_text)\n",
        "\n",
        "        return full_text.strip()\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"   Network error scraping {url}: {e}\")\n",
        "        return \"\"\n",
        "    except Exception as e:\n",
        "        print(f\"   Unexpected error scraping {url}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def deduplicate_with_lm(\n",
        "    items: List[EntityWithAttr],\n",
        "    batch_size: int = 15,\n",
        "    target_confidence: float = 0.85,\n",
        "    max_attempts: int = 4\n",
        ") -> List[EntityWithAttr]:\n",
        "    \"\"\"\n",
        "    Deduplicate entities using LLM with confidence-based retry logic\n",
        "\n",
        "    Key insight: LLMs can hallucinate, so we retry until confidence threshold is met.\n",
        "    This prevents cases like \"nitrogen uptake\", \"N uptake\", \"nitrogen absorption\"\n",
        "    being treated as separate entities.\n",
        "\n",
        "    Args:\n",
        "        items: List of entities to deduplicate\n",
        "        batch_size: Process entities in batches for efficiency\n",
        "        target_confidence: Minimum confidence score to accept (0-1)\n",
        "        max_attempts: Max retry attempts per batch\n",
        "\n",
        "    Returns:\n",
        "        Deduplicated list of entities\n",
        "    \"\"\"\n",
        "    if not items:\n",
        "        return []\n",
        "\n",
        "    def process_batch(batch: List[EntityWithAttr]) -> List[EntityWithAttr]:\n",
        "        \"\"\"Process a single batch with retry logic\"\"\"\n",
        "        for attempt in range(1, max_attempts + 1):\n",
        "            try:\n",
        "                pred = dedup_predictor(items=batch)\n",
        "                confidence = float(getattr(pred, \"confidence\", 0.0))\n",
        "\n",
        "                if confidence >= target_confidence:\n",
        "                    return pred.deduplicated\n",
        "\n",
        "                # Exponential backoff before retry\n",
        "                time.sleep(0.5 * (2 ** (attempt - 1)))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    Dedup attempt {attempt} failed: {e}\")\n",
        "                if attempt == max_attempts:\n",
        "                    return batch  # Return original on final failure\n",
        "\n",
        "        # If we exhaust attempts without reaching confidence, return last result\n",
        "        print(f\"     Dedup confidence {confidence:.2f} < {target_confidence} after {max_attempts} attempts\")\n",
        "        return pred.deduplicated if pred else batch\n",
        "\n",
        "    # Process in batches for efficiency\n",
        "    results = []\n",
        "    for i in range(0, len(items), batch_size):\n",
        "        batch = items[i:i + batch_size]\n",
        "        deduped = process_batch(batch)\n",
        "        results.extend(deduped)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def sanitize_mermaid_id(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert entity text into valid Mermaid diagram identifier\n",
        "\n",
        "    Rules:\n",
        "    - Remove special characters\n",
        "    - Replace spaces with underscores\n",
        "    - Ensure doesn't start with digit\n",
        "    \"\"\"\n",
        "    cleaned = re.sub(r'[^a-zA-Z0-9_\\s]', '', text)\n",
        "    cleaned = cleaned.strip().replace(' ', '_')\n",
        "\n",
        "    # Mermaid IDs can't start with numbers\n",
        "    if cleaned and cleaned[0].isdigit():\n",
        "        cleaned = 'n' + cleaned\n",
        "\n",
        "    return cleaned if cleaned else 'node'\n",
        "\n",
        "\n",
        "def triples_to_mermaid(\n",
        "    triples: List[Relation],\n",
        "    entity_list: List[str],\n",
        "    max_label_len: int = 40\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Convert relation triples to Mermaid flowchart syntax\n",
        "\n",
        "    Critical: Only includes triples where BOTH entities are in our validated list.\n",
        "    This prevents \"garbage nodes\" from LLM hallucinations.\n",
        "\n",
        "    Args:\n",
        "        triples: List of (subject, predicate, object) relations\n",
        "        entity_list: Validated entity names (from deduplication)\n",
        "        max_label_len: Max characters for edge labels\n",
        "\n",
        "    Returns:\n",
        "        Mermaid flowchart markdown string\n",
        "    \"\"\"\n",
        "    # Create case-insensitive lookup set\n",
        "    entity_set = {e.strip().lower() for e in entity_list}\n",
        "\n",
        "    lines = [\"flowchart LR\"]\n",
        "\n",
        "    for triple in triples:\n",
        "        subj_lower = triple.subj.strip().lower()\n",
        "        obj_lower = triple.obj.strip().lower()\n",
        "\n",
        "        # CRITICAL CHECK: Both entities must be validated\n",
        "        if subj_lower not in entity_set or obj_lower not in entity_set:\n",
        "            continue\n",
        "\n",
        "        # Create safe IDs and labels\n",
        "        subj_id = sanitize_mermaid_id(triple.subj)\n",
        "        obj_id = sanitize_mermaid_id(triple.obj)\n",
        "\n",
        "        # Truncate predicate if too long\n",
        "        predicate = triple.pred.strip()\n",
        "        if len(predicate) > max_label_len:\n",
        "            predicate = predicate[:max_label_len - 3] + \"...\"\n",
        "\n",
        "        # Mermaid syntax: node_id[\"Display Text\"] -->|Edge Label| node_id2[\"Display Text 2\"]\n",
        "        lines.append(f'    {subj_id}[\"{triple.subj}\"] -->|{predicate}| {obj_id}[\"{triple.obj}\"]')\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "def process_single_url(url: str, idx: int) -> Tuple[List[Tuple], str, List[str]]:\n",
        "    \"\"\"\n",
        "    Complete pipeline for a single URL: scrape â†’ extract â†’ deduplicate â†’ relate â†’ visualize\n",
        "\n",
        "    Returns:\n",
        "        (tags_rows, mermaid_code, entity_strings) or ([], \"\", []) on failure\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Processing URL {idx}: {url}\")\n",
        "    print('='*70)\n",
        "\n",
        "    # Step 1: Scrape content\n",
        "    print(\"  [1/4] Scraping text...\")\n",
        "    text = scrape_text_from_url(url)\n",
        "\n",
        "    if not text or len(text) < 100:\n",
        "        print(\"   Insufficient text scraped. Skipping.\")\n",
        "        return [], \"\", []\n",
        "\n",
        "    print(f\"  âœ“ Scraped {len(text):,} characters\")\n",
        "\n",
        "    # Step 2: Entity extraction\n",
        "    print(\"  [2/4] Extracting entities...\")\n",
        "    try:\n",
        "        # Truncate very long texts to avoid API limits\n",
        "        text_sample = text[:15000] if len(text) > 15000 else text\n",
        "        result = extractor(paragraph=text_sample)\n",
        "        raw_entities = result.entities or []\n",
        "    except Exception as e:\n",
        "        print(f\"   Entity extraction failed: {e}\")\n",
        "        return [], \"\", []\n",
        "\n",
        "    if not raw_entities:\n",
        "        print(\"   No entities extracted. Skipping.\")\n",
        "        return [], \"\", []\n",
        "\n",
        "    print(f\"  âœ“ Extracted {len(raw_entities)} raw entities\")\n",
        "\n",
        "    # Step 3: Deduplication (critical for data quality!)\n",
        "    print(\"  [3/4] Deduplicating entities...\")\n",
        "    unique_entities = deduplicate_with_lm(raw_entities)\n",
        "    print(f\"  âœ“ Deduplicated to {len(unique_entities)} unique entities\")\n",
        "\n",
        "    # Prepare tags for CSV\n",
        "    tags_rows = []\n",
        "    seen_tags: Set[str] = set()\n",
        "\n",
        "    for entity in unique_entities:\n",
        "        tag = entity.entity.strip()\n",
        "        tag_type = entity.attr_type.strip() if entity.attr_type else \"Unknown\"\n",
        "\n",
        "        # No duplicates per URL\n",
        "        tag_lower = tag.lower()\n",
        "        if tag_lower in seen_tags:\n",
        "            continue\n",
        "\n",
        "        seen_tags.add(tag_lower)\n",
        "        tags_rows.append((url, tag, tag_type))\n",
        "\n",
        "    # Step 4: Relation extraction\n",
        "    print(\"  [4/4] Extracting relations...\")\n",
        "    entity_strings = [e.entity for e in unique_entities]\n",
        "\n",
        "    try:\n",
        "        rel_result = rel_predictor(paragraph=text_sample, entities=entity_strings)\n",
        "        triples = rel_result.relations or []\n",
        "    except Exception as e:\n",
        "        print(f\"   Relation extraction failed: {e}\")\n",
        "        triples = []\n",
        "\n",
        "    print(f\"  âœ“ Extracted {len(triples)} relations\")\n",
        "\n",
        "    # Generate Mermaid diagram\n",
        "    mermaid_code = triples_to_mermaid(triples, entity_strings)\n",
        "\n",
        "    return tags_rows, mermaid_code, entity_strings\n"
      ],
      "metadata": {
        "id": "x9v_fSDnauZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Define URLs to Process\n",
        "# ----------------------------------------------------------------------------\n",
        "URLS = [\n",
        "    \"https://en.wikipedia.org/wiki/Sustainable_agriculture\",\n",
        "    \"https://www.nature.com/articles/d41586-025-03353-5\",\n",
        "    \"https://www.sciencedirect.com/science/article/pii/S1043661820315152\",\n",
        "    \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10457221/\",\n",
        "    \"https://www.fao.org/3/y4671e/y4671e06.htm\",\n",
        "    \"https://www.medscape.com/viewarticle/time-reconsider-tramadol-chronic-pain-2025a1000ria\",\n",
        "    \"https://www.sciencedirect.com/science/article/pii/S0378378220307088\",\n",
        "    \"https://www.frontiersin.org/news/2025/09/01/rectangle-telescope-finding-habitable-planets\",\n",
        "    \"https://www.medscape.com/viewarticle/second-dose-boosts-shingles-protection-adults-aged-65-years-2025a1000ro7\",\n",
        "    \"https://www.theguardian.com/global-development/2025/oct/13/astro-ambassadors-stargazers-himalayas-hanle-ladakh-india\"\n",
        "]\n",
        "\n",
        "print(f\"âœ“ {len(URLS)} URLs loaded for processing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_KmXLQravQr",
        "outputId": "6d18a94d-9011-4cc0-e84c-fa3dfc4f793b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ 10 URLs loaded for processing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Execute Pipeline on All URLs\n",
        "# ----------------------------------------------------------------------------\n",
        "# Create output directory\n",
        "output_dir = Path(\"dspy_outputs\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Storage for results\n",
        "all_tags = []\n",
        "mermaid_files = []\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STARTING PIPELINE EXECUTION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Process each URL with progress bar\n",
        "for idx, url in enumerate(tqdm(URLS, desc=\"Overall Progress\"), start=1):\n",
        "    # Process URL\n",
        "    tags_rows, mermaid_code, entity_strings = process_single_url(url, idx)\n",
        "\n",
        "    # Store tags\n",
        "    all_tags.extend(tags_rows)\n",
        "\n",
        "    # Save Mermaid diagram\n",
        "    if mermaid_code:\n",
        "        mermaid_path = output_dir / f\"mermaid_{idx}.md\"\n",
        "        with open(mermaid_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"```mermaid\\n\")\n",
        "            f.write(mermaid_code)\n",
        "            f.write(\"\\n```\")\n",
        "\n",
        "        mermaid_files.append(str(mermaid_path))\n",
        "        print(f\"   Saved: {mermaid_path.name}\")\n",
        "\n",
        "    # Rate limiting: pause between URLs to respect API limits\n",
        "    if idx < len(URLS):\n",
        "        time.sleep(2)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PIPELINE COMPLETE\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4ca670fda0e34989a25417042897a7bf",
            "c50352356ec743b2ab165dd9923d1dee",
            "3e902e3574c3451882c5d1b0ed1432a0",
            "31cecd66f5614561b675d1504625d96b",
            "4c33241109a34d8bb9a70acf57354c69",
            "0ca908163d2f4f1aa18500d2d349e2cf",
            "86909d9f8bab41849aac75c4584dcae4",
            "27b5882e6ace417f85a81d06249ecf75",
            "15c538e34b5f46db8c0514b69e06cf5f",
            "d40a7c893426477d9d2cbcac8d0058bf",
            "c5d14e2dfff145309e467ef7d3db7f4f"
          ]
        },
        "id": "ETnp15tgayhf",
        "outputId": "a688f6b3-f2e6-415f-97ef-1d8f6411f4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STARTING PIPELINE EXECUTION\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Overall Progress:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ca670fda0e34989a25417042897a7bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Processing URL 1: https://en.wikipedia.org/wiki/Sustainable_agriculture\n",
            "======================================================================\n",
            "  [1/4] Scraping text...\n",
            "  âœ“ Scraped 136,163 characters\n",
            "  [2/4] Extracting entities...\n",
            "  âœ“ Extracted 116 raw entities\n",
            "  [3/4] Deduplicating entities...\n",
            "  âœ“ Deduplicated to 113 unique entities\n",
            "  [4/4] Extracting relations...\n",
            "  âœ“ Extracted 141 relations\n",
            "   Saved: mermaid_1.md\n",
            "\n",
            "======================================================================\n",
            "Processing URL 2: https://www.nature.com/articles/d41586-025-03353-5\n",
            "======================================================================\n",
            "  [1/4] Scraping text...\n",
            "  âœ“ Scraped 13,717 characters\n",
            "  [2/4] Extracting entities...\n",
            "  âœ“ Extracted 28 raw entities\n",
            "  [3/4] Deduplicating entities...\n",
            "  âœ“ Deduplicated to 27 unique entities\n",
            "  [4/4] Extracting relations...\n",
            "  âœ“ Extracted 19 relations\n",
            "   Saved: mermaid_2.md\n",
            "\n",
            "======================================================================\n",
            "Processing URL 3: https://www.sciencedirect.com/science/article/pii/S1043661820315152\n",
            "======================================================================\n",
            "  [1/4] Scraping text...\n",
            "   Network error scraping https://www.sciencedirect.com/science/article/pii/S1043661820315152: 403 Client Error: Forbidden for url: https://www.sciencedirect.com/science/article/pii/S1043661820315152\n",
            "   Insufficient text scraped. Skipping.\n",
            "\n",
            "======================================================================\n",
            "Processing URL 4: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10457221/\n",
            "======================================================================\n",
            "  [1/4] Scraping text...\n",
            "   Network error scraping https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10457221/: 403 Client Error: Forbidden for url: https://pmc.ncbi.nlm.nih.gov/articles/PMC10457221/\n",
            "   Insufficient text scraped. Skipping.\n",
            "\n",
            "======================================================================\n",
            "Processing URL 5: https://www.fao.org/3/y4671e/y4671e06.htm\n",
            "======================================================================\n",
            "  [1/4] Scraping text...\n",
            "  âœ“ Scraped 20,046 characters\n",
            "  [2/4] Extracting entities...\n",
            "  âœ“ Extracted 66 raw entities\n",
            "  [3/4] Deduplicating entities...\n",
            "  âœ“ Deduplicated to 64 unique entities\n",
            "  [4/4] Extracting relations...\n",
            "  âœ“ Extracted 58 relations\n",
            "   Saved: mermaid_5.md\n",
            "\n",
            "======================================================================\n",
            "Processing URL 6: https://www.medscape.com/viewarticle/time-reconsider-tramadol-chronic-pain-2025a1000ria\n",
            "======================================================================\n",
            "  [1/4] Scraping text...\n",
            "  âœ“ Scraped 21,738 characters\n",
            "  [2/4] Extracting entities...\n",
            "  âœ“ Extracted 37 raw entities\n",
            "  [3/4] Deduplicating entities...\n",
            "  âœ“ Deduplicated to 36 unique entities\n",
            "  [4/4] Extracting relations...\n",
            "  âœ“ Extracted 52 relations\n",
            "   Saved: mermaid_6.md\n",
            "\n",
            "======================================================================\n",
            "Processing URL 7: https://www.sciencedirect.com/science/article/pii/S0378378220307088\n",
            "======================================================================\n",
            "  [1/4] Scraping text...\n",
            "   Network error scraping https://www.sciencedirect.com/science/article/pii/S0378378220307088: 403 Client Error: Forbidden for url: https://www.sciencedirect.com/science/article/pii/S0378378220307088\n",
            "   Insufficient text scraped. Skipping.\n",
            "\n",
            "======================================================================\n",
            "Processing URL 8: https://www.frontiersin.org/news/2025/09/01/rectangle-telescope-finding-habitable-planets\n",
            "======================================================================\n",
            "  [1/4] Scraping text...\n",
            "  âœ“ Scraped 11,699 characters\n",
            "  [2/4] Extracting entities...\n",
            "  âœ“ Extracted 42 raw entities\n",
            "  [3/4] Deduplicating entities...\n",
            "  âœ“ Deduplicated to 40 unique entities\n",
            "  [4/4] Extracting relations...\n",
            "  âœ“ Extracted 45 relations\n",
            "   Saved: mermaid_8.md\n",
            "\n",
            "======================================================================\n",
            "Processing URL 9: https://www.medscape.com/viewarticle/second-dose-boosts-shingles-protection-adults-aged-65-years-2025a1000ro7\n",
            "======================================================================\n",
            "  [1/4] Scraping text...\n",
            "  âœ“ Scraped 15,614 characters\n",
            "  [2/4] Extracting entities...\n",
            "  âœ“ Extracted 27 raw entities\n",
            "  [3/4] Deduplicating entities...\n",
            "  âœ“ Deduplicated to 26 unique entities\n",
            "  [4/4] Extracting relations...\n",
            "  âœ“ Extracted 34 relations\n",
            "   Saved: mermaid_9.md\n",
            "\n",
            "======================================================================\n",
            "Processing URL 10: https://www.theguardian.com/global-development/2025/oct/13/astro-ambassadors-stargazers-himalayas-hanle-ladakh-india\n",
            "======================================================================\n",
            "  [1/4] Scraping text...\n",
            "  âœ“ Scraped 15,354 characters\n",
            "  [2/4] Extracting entities...\n",
            "  âœ“ Extracted 37 raw entities\n",
            "  [3/4] Deduplicating entities...\n",
            "  âœ“ Deduplicated to 37 unique entities\n",
            "  [4/4] Extracting relations...\n",
            "  âœ“ Extracted 52 relations\n",
            "   Saved: mermaid_10.md\n",
            "\n",
            "======================================================================\n",
            "PIPELINE COMPLETE\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Generate CSV Output\n",
        "# ----------------------------------------------------------------------------\n",
        "print(\"\\n Generating tags.csv...\")\n",
        "\n",
        "df = pd.DataFrame(all_tags, columns=[\"link\", \"tag\", \"tag_type\"])\n",
        "\n",
        "# Save to CSV\n",
        "csv_path = output_dir / \"tags.csv\"\n",
        "df.to_csv(csv_path, index=False, encoding='utf-8')\n",
        "\n",
        "print(f\"âœ“ Saved {len(df)} tags to {csv_path}\")\n",
        "print(f\"\\nTag type distribution:\")\n",
        "print(df['tag_type'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t0RewKna29D",
        "outputId": "b50695b6-be62-4209-f0a4-40463eb5c03f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Generating tags.csv...\n",
            "âœ“ Saved 341 tags to dspy_outputs/tags.csv\n",
            "\n",
            "Tag type distribution:\n",
            "tag_type\n",
            "Concept                55\n",
            "Process                40\n",
            "Technology             24\n",
            "Organization           23\n",
            "Person                 16\n",
            "                       ..\n",
            "Medical Metric          1\n",
            "Environmental Issue     1\n",
            "Role                    1\n",
            "Celestial Pattern       1\n",
            "Topic                   1\n",
            "Name: count, Length: 62, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Create Downloadable ZIP\n",
        "# ----------------------------------------------------------------------------\n",
        "print(\"\\n Creating downloadable archive...\")\n",
        "\n",
        "zip_path = \"dspy_assignment_output.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'w', compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    # Add all Mermaid diagrams\n",
        "    for mermaid_file in mermaid_files:\n",
        "        zf.write(mermaid_file, arcname=Path(mermaid_file).name)\n",
        "\n",
        "    # Add CSV\n",
        "    zf.write(csv_path, arcname=\"tags.csv\")\n",
        "\n",
        "print(f\"âœ“ Created {zip_path}\")\n",
        "print(f\"  Contains: {len(mermaid_files)} Mermaid diagrams + 1 CSV\")\n",
        "print(\"\\nðŸ“¥ Download from Files panel (left sidebar) in Colab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4AZoynPa56c",
        "outputId": "df5a3cda-d4a8-472c-dc84-ac81ea8b45a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Creating downloadable archive...\n",
            "âœ“ Created dspy_assignment_output.zip\n",
            "  Contains: 7 Mermaid diagrams + 1 CSV\n",
            "\n",
            "ðŸ“¥ Download from Files panel (left sidebar) in Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Display Results Summary\n",
        "# ----------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FINAL RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n Statistics:\")\n",
        "print(f\"  â€¢ URLs processed: {len(mermaid_files)}/{len(URLS)}\")\n",
        "print(f\"  â€¢ Total entities extracted: {len(df)}\")\n",
        "print(f\"  â€¢ Unique entity types: {df['tag_type'].nunique()}\")\n",
        "\n",
        "print(f\"\\n Sample from tags.csv:\")\n",
        "print(df.head(15).to_string(index=False))\n",
        "\n",
        "print(f\"\\n Generated files:\")\n",
        "for f in mermaid_files:\n",
        "    print(f\"  â€¢ {Path(f).name}\")\n",
        "print(f\"  â€¢ tags.csv\")\n",
        "\n",
        "print(f\"\\n Assignment complete! Download '{zip_path}' for submission.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlO5pxoVa9aw",
        "outputId": "7709ae39-5c35-4486-c66a-e3674e9ae752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "FINAL RESULTS\n",
            "======================================================================\n",
            "\n",
            " Statistics:\n",
            "  â€¢ URLs processed: 7/10\n",
            "  â€¢ Total entities extracted: 341\n",
            "  â€¢ Unique entity types: 62\n",
            "\n",
            " Sample from tags.csv:\n",
            "                                                 link                      tag           tag_type\n",
            "https://en.wikipedia.org/wiki/Sustainable_agriculture  sustainable agriculture            Process\n",
            "https://en.wikipedia.org/wiki/Sustainable_agriculture       ecosystem services            Concept\n",
            "https://en.wikipedia.org/wiki/Sustainable_agriculture sustainable food systems             System\n",
            "https://en.wikipedia.org/wiki/Sustainable_agriculture           climate change EnvironmentalIssue\n",
            "https://en.wikipedia.org/wiki/Sustainable_agriculture greenhouse gas emissions EnvironmentalIssue\n",
            "https://en.wikipedia.org/wiki/Sustainable_agriculture           water scarcity EnvironmentalIssue\n",
            "https://en.wikipedia.org/wiki/Sustainable_agriculture          water pollution EnvironmentalIssue\n",
            "https://en.wikipedia.org/wiki/Sustainable_agriculture         land degradation EnvironmentalIssue\n",
            "https://en.wikipedia.org/wiki/Sustainable_agriculture            deforestation EnvironmentalIssue\n",
            "https://en.wikipedia.org/wiki/Sustainable_agriculture             permaculture            Process\n",
            "https://en.wikipedia.org/wiki/Sustainable_agriculture             agroforestry            Process\n",
            "https://en.wikipedia.org/wiki/Sustainable_agriculture            mixed farming            Process\n",
            "https://en.wikipedia.org/wiki/Sustainable_agriculture        multiple cropping            Process\n",
            "https://en.wikipedia.org/wiki/Sustainable_agriculture            crop rotation            Process\n",
            "https://en.wikipedia.org/wiki/Sustainable_agriculture             land sparing            Process\n",
            "\n",
            " Generated files:\n",
            "  â€¢ mermaid_1.md\n",
            "  â€¢ mermaid_2.md\n",
            "  â€¢ mermaid_5.md\n",
            "  â€¢ mermaid_6.md\n",
            "  â€¢ mermaid_8.md\n",
            "  â€¢ mermaid_9.md\n",
            "  â€¢ mermaid_10.md\n",
            "  â€¢ tags.csv\n",
            "\n",
            " Assignment complete! Download 'dspy_assignment_output.zip' for submission.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Validate Mermaid Syntax (Optional)\n",
        "# ----------------------------------------------------------------------------\n",
        "print(\"\\n Validating Mermaid diagrams...\")\n",
        "\n",
        "validation_errors = []\n",
        "for mermaid_file in mermaid_files:\n",
        "    with open(mermaid_file, 'r', encoding='utf-8') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # Basic syntax checks\n",
        "    if \"flowchart LR\" not in content:\n",
        "        validation_errors.append(f\"{Path(mermaid_file).name}: Missing flowchart declaration\")\n",
        "\n",
        "    if content.count('```') != 2:\n",
        "        validation_errors.append(f\"{Path(mermaid_file).name}: Incorrect code fence count\")\n",
        "\n",
        "if validation_errors:\n",
        "    print(\" Validation issues found:\")\n",
        "    for error in validation_errors:\n",
        "        print(f\"  â€¢ {error}\")\n",
        "else:\n",
        "    print(\"âœ“ All Mermaid diagrams valid!\")\n",
        "    print(\"  Test them at: https://mermaid.live/\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" PIPELINE EXECUTION COMPLETE\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLp1C-wkbDB8",
        "outputId": "15b7ecf2-808d-4cfa-92bd-29e2d7065c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validating Mermaid diagrams...\n",
            "âœ“ All Mermaid diagrams valid!\n",
            "  Test them at: https://mermaid.live/\n",
            "\n",
            "======================================================================\n",
            " PIPELINE EXECUTION COMPLETE\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}