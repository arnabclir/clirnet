{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!uv pip install dspy-ai requests beautifulsoup4 pandas pydantic\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "per1ldiM9Yew",
        "outputId": "f56c4ec9-55b5-436a-ef73-0674ea86dceb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m80 packages\u001b[0m \u001b[2min 833ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m12 packages\u001b[0m \u001b[2min 651ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m12 packages\u001b[0m \u001b[2min 63ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1masyncer\u001b[0m\u001b[2m==0.0.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbackoff\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcolorlog\u001b[0m\u001b[2m==6.10.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdiskcache\u001b[0m\u001b[2m==5.6.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdspy\u001b[0m\u001b[2m==3.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdspy-ai\u001b[0m\u001b[2m==3.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfastuuid\u001b[0m\u001b[2m==0.14.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgepa\u001b[0m\u001b[2m==0.0.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjson-repair\u001b[0m\u001b[2m==0.52.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlitellm\u001b[0m\u001b[2m==1.79.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmagicattr\u001b[0m\u001b[2m==0.1.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1moptuna\u001b[0m\u001b[2m==4.5.0\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import dspy\n",
        "import copy\n",
        "from typing import List, Optional, Literal, Dict, Union\n",
        "from dspy.adapters import XMLAdapter\n",
        "from pydantic import BaseModel, Field\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "qMB4uelY9qXv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuring API\n",
        "API_KEY = \"ak_1vd4a60HG1CO3pF17J7bk8YS1Wd3m\"\n",
        "\n",
        "main_lm = dspy.LM(\n",
        "    \"openai/LongCat-Flash-Chat\",\n",
        "    api_key=API_KEY,\n",
        "    api_base=\"https://api.longcat.chat/openai/v1\"\n",
        ")\n",
        "dspy.settings.configure(lm=main_lm, adapter=dspy.XMLAdapter())\n",
        "print(\"API configured successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rakppYyb9yKh",
        "outputId": "09988513-a398-439d-ddec-fe4df3a9d02b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API configured successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. ENTITY EXTRACTION\n",
        "class EntityWithAttr(BaseModel):\n",
        "    entity: str = Field(description=\"the named entity\")\n",
        "    attr_type: str = Field(description=\"semantic type of the entity (e.g. Drug, Disease, Symptom, etc.)\")\n",
        "\n",
        "# Instructions to the LLM\n",
        "class ExtractEntities(dspy.Signature):\n",
        "    paragraph: str = dspy.InputField(desc=\"input paragraph\")\n",
        "    entities: List[EntityWithAttr] = dspy.OutputField(desc=\"list of entities and their attribute types\")\n",
        "\n",
        "extractor = dspy.Predict(ExtractEntities)\n",
        "\n",
        "# 2. DEDUPLICATION WITH CONFIDENCE LOOPS\n",
        "class DeduplicateEntities(dspy.Signature):\n",
        "    items: List[EntityWithAttr] = dspy.InputField(desc=\"batch of entities to deduplicate\")\n",
        "    deduplicated: List[EntityWithAttr] = dspy.OutputField(desc=\"deduplicated list\")\n",
        "    confidence: float = dspy.OutputField(\n",
        "        desc=\"confidence (0-1) that every item in deduplicated is semantically distinct\"\n",
        "    )\n",
        "\n",
        "dedup_predictor = dspy.ChainOfThought(DeduplicateEntities)\n",
        "\n",
        "def deduplicate_with_lm(\n",
        "    items: List[EntityWithAttr],\n",
        "    *,\n",
        "    batch_size: int = 10,\n",
        "    target_confidence: float = 0.9,\n",
        ") -> List[EntityWithAttr]:\n",
        "    if not items:\n",
        "        return []\n",
        "    def _process_batch(batch: List[EntityWithAttr]) -> List[EntityWithAttr]:\n",
        "        while True:\n",
        "            pred = dedup_predictor(items=batch)\n",
        "            if pred.confidence >= target_confidence:\n",
        "                return pred.deduplicated\n",
        "\n",
        "    # Spliting items into smaller batches and process\n",
        "    results = []\n",
        "    for i in range(0, len(items), batch_size):\n",
        "        batch = items[i : i + batch_size]\n",
        "        results.extend(_process_batch(batch))\n",
        "    return results\n",
        "\n",
        "# 3. RELATION EXTRACTION\n",
        "\n",
        "class Relation(BaseModel):\n",
        "    subj: str = Field(description=\"subject entity (exact string as in deduplicated list)\")\n",
        "    pred: str = Field(description=\"short predicate / relation phrase\")\n",
        "    obj:  str = Field(description=\"object entity (exact string as in deduplicated list)\")\n",
        "\n",
        "class ExtractRelations(dspy.Signature):\n",
        "    paragraph: str = dspy.InputField(desc=\"original paragraph\")\n",
        "    entities:  List[str] = dspy.InputField(desc=\"list of deduplicated entity strings\")\n",
        "    relations: List[Relation] = dspy.OutputField(desc=\"list of subject-predicate-object triples\")\n",
        "\n",
        "rel_predictor = dspy.ChainOfThought(ExtractRelations)\n",
        "\n",
        "# 4. MERMAID DIAGRAM GENERATION\n",
        "def triples_to_mermaid(\n",
        "    triples: List[Relation],\n",
        "    entity_list: List[str],\n",
        "    max_label_len: int = 40\n",
        ") -> str:\n",
        "    entity_set = {e.strip().lower() for e in entity_list}\n",
        "    lines = [\"flowchart LR\"]\n",
        "\n",
        "    def _make_id(s: str) -> str:\n",
        "        s = re.sub(r'[^\\w\\s]', '', s)    #Removing special chars\n",
        "        s = s.strip().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
        "        return s[:50]\n",
        "\n",
        "    def _escape_label(s: str) -> str:\n",
        "        s = s.replace('\"', \"'\")\n",
        "        s = s.replace(\"'\", \"\")\n",
        "        s = s.replace(\"#\", \"\")\n",
        "        s = s.replace(\";\", \",\")\n",
        "        return s.strip()\n",
        "\n",
        "    for t in triples:\n",
        "        subj_norm, obj_norm = t.subj.strip().lower(), t.obj.strip().lower()\n",
        "\n",
        "        if obj_norm in entity_set:\n",
        "            src, dst, lbl = t.subj, t.obj, t.pred\n",
        "        elif subj_norm in entity_set:\n",
        "            src, dst, lbl = t.obj, t.subj, t.pred\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        lbl = _escape_label(lbl)\n",
        "        if len(lbl) > max_label_len:\n",
        "            lbl = lbl[:max_label_len - 3] + \"...\"\n",
        "        lbl = lbl.rstrip('.')\n",
        "\n",
        "        src_id, dst_id = _make_id(src), _make_id(dst)\n",
        "        src_label = _escape_label(src)\n",
        "        dst_label = _escape_label(dst)\n",
        "\n",
        "        lines.append(f'    {src_id}[\"{src_label}\"] -->|{lbl}| {dst_id}[\"{dst_label}\"]')\n",
        "\n",
        "    return \"\\n\".join(lines)\n"
      ],
      "metadata": {
        "id": "WA9r0Rv--QK0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_url(url):\n",
        "    try:\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
        "        }\n",
        "        response = requests.get(url, headers=headers, timeout=30)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        for script in soup([\"script\", \"style\", \"nav\", \"footer\", \"header\"]):\n",
        "            script.decompose()\n",
        "\n",
        "        text = soup.get_text(separator=' ', strip=True)\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        words = text.split()[:3000]    #Limit to first 3000 words\n",
        "        text = ' '.join(words)\n",
        "\n",
        "        return text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   Error scraping {url}: {str(e)}\")\n",
        "        return \"\"\n"
      ],
      "metadata": {
        "id": "TZaEsIfaBQWq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PIPELINE\n",
        "\n",
        "# List of URLs\n",
        "urls = [\n",
        "    \"https://en.wikipedia.org/wiki/Sustainable_agriculture\",\n",
        "    \"https://www.nature.com/articles/d41586-025-03353-5\",\n",
        "    \"https://www.sciencedirect.com/science/article/pii/S1043661820315152\",\n",
        "    \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10457221/\",\n",
        "    \"https://www.fao.org/3/y4671e/y4671e06.htm\",\n",
        "    \"https://www.medscape.com/viewarticle/time-reconsider-tramadol-chronic-pain-2025a1000ria\",\n",
        "    \"https://www.sciencedirect.com/science/article/pii/S0378378220307088\",\n",
        "    \"https://www.frontiersin.org/news/2025/09/01/rectangle-telescope-finding-habitable-planets\",\n",
        "    \"https://www.medscape.com/viewarticle/second-dose-boosts-shingles-protection-adults-aged-65-years-2025a1000ro7\",\n",
        "    \"https://www.theguardian.com/global-development/2025/oct/13/astro-ambassadors-stargazers-himalayas-hanle-ladakh-india\"\n",
        "]\n",
        "\n",
        "all_csv_data = []\n",
        "successful_count = 0\n",
        "\n",
        "for idx, url in enumerate(urls, 1):\n",
        "    print(f\"Processing URL {idx}/{len(urls)}: {url}\")\n",
        "    print(f\"{'-'*70}\")\n",
        "\n",
        "    print(\"1. Scraping content...\")\n",
        "    paragraph = scrape_url(url)\n",
        "\n",
        "    if not paragraph:\n",
        "        print(\"Failed to scrape content, skipping URL\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Scraped {len(paragraph)} characters\")\n",
        "\n",
        "    try:\n",
        "\n",
        "        print(\"2. Extracting entities...\")\n",
        "        extracted = extractor(paragraph=paragraph)\n",
        "        print(f\"Extracted {len(extracted.entities)} entities\")\n",
        "\n",
        "        if not extracted.entities:\n",
        "            print(\"No entities found! Skipping URL\")\n",
        "            continue\n",
        "\n",
        "        print(\"3. Deduplicating entities...\")\n",
        "        unique = deduplicate_with_lm(\n",
        "            extracted.entities,\n",
        "            batch_size=10,\n",
        "            target_confidence=0.9\n",
        "        )\n",
        "        print(f\"Deduplicated to {len(unique)} unique entities\")\n",
        "\n",
        "        print(\"4. Extracting relations...\")\n",
        "        entity_strings = [e.entity for e in unique]\n",
        "        rel_out = rel_predictor(paragraph=paragraph, entities=entity_strings)\n",
        "        print(f\"Extracted {len(rel_out.relations)} relations\")\n",
        "\n",
        "        print(\"5. Generating Mermaid diagram...\")\n",
        "        mermaid_code = triples_to_mermaid(rel_out.relations, entity_strings)\n",
        "\n",
        "        with open(f'mermaid_{idx}.md', 'w', encoding='utf-8') as f:\n",
        "            f.write(mermaid_code)\n",
        "        print(f\"Saved mermaid_{idx}.md\")\n",
        "\n",
        "        for entity in unique:\n",
        "            all_csv_data.append({\n",
        "                'link': url,\n",
        "                'tag': entity.entity,\n",
        "                'tag_type': entity.attr_type\n",
        "            })\n",
        "\n",
        "        successful_count += 1\n",
        "        print(f\"Successfully processed URL {idx}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing URL: {str(e)}\")\n",
        "        continue\n",
        "\n",
        "\n",
        "# SAVE THE CSV FILE\n",
        "\n",
        "print(f\"\\n{'-'*70}\")\n",
        "print(\"Saving CSV...\")\n",
        "df = pd.DataFrame(all_csv_data)\n",
        "df = df.drop_duplicates(subset=['link', 'tag'])\n",
        "df.to_csv('tags.csv', index=False)\n",
        "\n",
        "print(f\"\\n ASSIGNMENT COMPLETE!\")\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"  - Successfully processed: {successful_count}/{len(urls)} URLs\")\n",
        "print(f\"  - Generated {successful_count} Mermaid diagrams\")\n",
        "print(f\"  - Saved tags.csv with {len(df)} rows\")\n",
        "print(f\"\\n{'-'*70}\")\n",
        "print(\"Sample CSV data (first 10 rows):\")\n",
        "print(df.head(10).to_string())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX4rAMtjB4cQ",
        "outputId": "36c893e5-bb73-4725-9602-bf2be8634795"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing URL 1/10: https://en.wikipedia.org/wiki/Sustainable_agriculture\n",
            "----------------------------------------------------------------------\n",
            "1. Scraping content...\n",
            "Scraped 19676 characters\n",
            "2. Extracting entities...\n",
            "Extracted 68 entities\n",
            "3. Deduplicating entities...\n",
            "Deduplicated to 68 unique entities\n",
            "4. Extracting relations...\n",
            "Extracted 81 relations\n",
            "5. Generating Mermaid diagram...\n",
            "Saved mermaid_1.md\n",
            "Successfully processed URL 1\n",
            "Processing URL 2/10: https://www.nature.com/articles/d41586-025-03353-5\n",
            "----------------------------------------------------------------------\n",
            "1. Scraping content...\n",
            "Scraped 5898 characters\n",
            "2. Extracting entities...\n",
            "Extracted 23 entities\n",
            "3. Deduplicating entities...\n",
            "Deduplicated to 23 unique entities\n",
            "4. Extracting relations...\n",
            "Extracted 13 relations\n",
            "5. Generating Mermaid diagram...\n",
            "Saved mermaid_2.md\n",
            "Successfully processed URL 2\n",
            "Processing URL 3/10: https://www.sciencedirect.com/science/article/pii/S1043661820315152\n",
            "----------------------------------------------------------------------\n",
            "1. Scraping content...\n",
            "   Error scraping https://www.sciencedirect.com/science/article/pii/S1043661820315152: 403 Client Error: Forbidden for url: https://www.sciencedirect.com/science/article/pii/S1043661820315152\n",
            "Failed to scrape content, skipping URL\n",
            "Processing URL 4/10: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10457221/\n",
            "----------------------------------------------------------------------\n",
            "1. Scraping content...\n",
            "Scraped 19261 characters\n",
            "2. Extracting entities...\n",
            "Extracted 70 entities\n",
            "3. Deduplicating entities...\n",
            "Deduplicated to 70 unique entities\n",
            "4. Extracting relations...\n",
            "Extracted 55 relations\n",
            "5. Generating Mermaid diagram...\n",
            "Saved mermaid_4.md\n",
            "Successfully processed URL 4\n",
            "Processing URL 5/10: https://www.fao.org/3/y4671e/y4671e06.htm\n",
            "----------------------------------------------------------------------\n",
            "1. Scraping content...\n",
            "Scraped 19930 characters\n",
            "2. Extracting entities...\n",
            "Extracted 78 entities\n",
            "3. Deduplicating entities...\n",
            "Deduplicated to 78 unique entities\n",
            "4. Extracting relations...\n",
            "Extracted 118 relations\n",
            "5. Generating Mermaid diagram...\n",
            "Saved mermaid_5.md\n",
            "Successfully processed URL 5\n",
            "Processing URL 6/10: https://www.medscape.com/viewarticle/time-reconsider-tramadol-chronic-pain-2025a1000ria\n",
            "----------------------------------------------------------------------\n",
            "1. Scraping content...\n",
            "Scraped 8593 characters\n",
            "2. Extracting entities...\n",
            "Extracted 74 entities\n",
            "3. Deduplicating entities...\n",
            "Deduplicated to 72 unique entities\n",
            "4. Extracting relations...\n",
            "Extracted 52 relations\n",
            "5. Generating Mermaid diagram...\n",
            "Saved mermaid_6.md\n",
            "Successfully processed URL 6\n",
            "Processing URL 7/10: https://www.sciencedirect.com/science/article/pii/S0378378220307088\n",
            "----------------------------------------------------------------------\n",
            "1. Scraping content...\n",
            "   Error scraping https://www.sciencedirect.com/science/article/pii/S0378378220307088: 403 Client Error: Forbidden for url: https://www.sciencedirect.com/science/article/pii/S0378378220307088\n",
            "Failed to scrape content, skipping URL\n",
            "Processing URL 8/10: https://www.frontiersin.org/news/2025/09/01/rectangle-telescope-finding-habitable-planets\n",
            "----------------------------------------------------------------------\n",
            "1. Scraping content...\n",
            "Scraped 9359 characters\n",
            "2. Extracting entities...\n",
            "Extracted 35 entities\n",
            "3. Deduplicating entities...\n",
            "Deduplicated to 29 unique entities\n",
            "4. Extracting relations...\n",
            "Extracted 34 relations\n",
            "5. Generating Mermaid diagram...\n",
            "Saved mermaid_8.md\n",
            "Successfully processed URL 8\n",
            "Processing URL 9/10: https://www.medscape.com/viewarticle/second-dose-boosts-shingles-protection-adults-aged-65-years-2025a1000ro7\n",
            "----------------------------------------------------------------------\n",
            "1. Scraping content...\n",
            "Scraped 6113 characters\n",
            "2. Extracting entities...\n",
            "Extracted 33 entities\n",
            "3. Deduplicating entities...\n",
            "Deduplicated to 31 unique entities\n",
            "4. Extracting relations...\n",
            "Extracted 27 relations\n",
            "5. Generating Mermaid diagram...\n",
            "Saved mermaid_9.md\n",
            "Successfully processed URL 9\n",
            "Processing URL 10/10: https://www.theguardian.com/global-development/2025/oct/13/astro-ambassadors-stargazers-himalayas-hanle-ladakh-india\n",
            "----------------------------------------------------------------------\n",
            "1. Scraping content...\n",
            "Scraped 9080 characters\n",
            "2. Extracting entities...\n",
            "Extracted 52 entities\n",
            "3. Deduplicating entities...\n",
            "Deduplicated to 52 unique entities\n",
            "4. Extracting relations...\n",
            "Extracted 80 relations\n",
            "5. Generating Mermaid diagram...\n",
            "Saved mermaid_10.md\n",
            "Successfully processed URL 10\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Saving CSV...\n",
            "\n",
            " ASSIGNMENT COMPLETE!\n",
            "\n",
            "Summary:\n",
            "  - Successfully processed: 8/10 URLs\n",
            "  - Generated 8 Mermaid diagrams\n",
            "  - Saved tags.csv with 422 rows\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Sample CSV data (first 10 rows):\n",
            "                                                    link                       tag               tag_type\n",
            "0  https://en.wikipedia.org/wiki/Sustainable_agriculture   Sustainable agriculture                Concept\n",
            "1  https://en.wikipedia.org/wiki/Sustainable_agriculture        Shade-grown coffee  Agricultural Practice\n",
            "2  https://en.wikipedia.org/wiki/Sustainable_agriculture               Polyculture  Agricultural Practice\n",
            "3  https://en.wikipedia.org/wiki/Sustainable_agriculture        Ecosystem services                Concept\n",
            "4  https://en.wikipedia.org/wiki/Sustainable_agriculture            Climate change    Environmental Issue\n",
            "5  https://en.wikipedia.org/wiki/Sustainable_agriculture  Greenhouse gas emissions    Environmental Issue\n",
            "6  https://en.wikipedia.org/wiki/Sustainable_agriculture            Water scarcity    Environmental Issue\n",
            "7  https://en.wikipedia.org/wiki/Sustainable_agriculture           Water pollution    Environmental Issue\n",
            "8  https://en.wikipedia.org/wiki/Sustainable_agriculture          Land degradation    Environmental Issue\n",
            "9  https://en.wikipedia.org/wiki/Sustainable_agriculture             Deforestation    Environmental Issue\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading all files\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"Downloading all files...\\n\")\n",
        "\n",
        "if os.path.exists('tags.csv'):\n",
        "    files.download('tags.csv')\n",
        "    print(\"Downloaded tags.csv\")\n",
        "\n",
        "for i in range(1, 11):\n",
        "    filename = f'mermaid_{i}.md'\n",
        "    if os.path.exists(filename):\n",
        "        files.download(filename)\n",
        "        print(f\"Downloaded {filename}\")\n",
        "\n",
        "print(\"\\nAll files downloaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "JLDMg6UiJjhQ",
        "outputId": "182fc33c-9d6c-4c48-9042-e2c3c36a8b3b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading all files...\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f2117831-0a40-4282-87bd-f0c12d563e37\", \"tags.csv\", 42407)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded tags.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_990d018f-4c17-4093-b6f7-86a19b2314a2\", \"mermaid_1.md\", 8300)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded mermaid_1.md\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_016c1ffc-80da-40d7-8e9e-6a64f42f1356\", \"mermaid_2.md\", 1241)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded mermaid_2.md\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5f800cee-d7b6-4564-a2df-25cd13f122a8\", \"mermaid_4.md\", 4675)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded mermaid_4.md\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c147483f-d653-4e9c-98c9-38deaa73752b\", \"mermaid_5.md\", 13038)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded mermaid_5.md\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ebc4aa7a-7dd1-4b9e-9b25-08215a32a1b5\", \"mermaid_6.md\", 4636)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded mermaid_6.md\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e32702cf-3976-49b9-bf1d-3e72431fb5a9\", \"mermaid_8.md\", 3456)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded mermaid_8.md\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_41dfdea1-7381-4cf6-82b9-2b62f6b7ab4d\", \"mermaid_9.md\", 3150)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded mermaid_9.md\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_00409e5d-ed81-4db2-808a-08f629622643\", \"mermaid_10.md\", 6783)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded mermaid_10.md\n",
            "\n",
            "All files downloaded!\n"
          ]
        }
      ]
    }
  ]
}