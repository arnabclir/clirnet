Here is the detailed transcript and the Minutes of the Meeting (MoM) based on the recording provided.

### **Part 1: Detailed Transcript**

**Attendees:**
*   **AS:** Arnab Saha (Manager/Lead)
*   **TB:** Tamalika Basak (Presenter)
*   **UB:** Udipto Bar (Team Member/“Ashu”)

**(00:00 - 00:45)**
**TB:** ...a list of challenges we are facing while reviewing the automated content references. First one is the absence of the in-text citations. Sir, whenever we are getting those references...
**AS:** (Interrupting) The in-text quality that is being generated, is that okay?
**TB:** Sir, if we are checking the informations from the article, the informations are there, and information is up to the... means... as per the article also. And wherever...
**AS:** (Interrupting) But the article is being written... Udipto, I don’t want you to jump in right now. Either you should have f***ing prepared with her before the meeting, or you shut the f*** up right now. There is *no* understanding of what time value is for anybody. Everyone has to sit together and talk? Sit together and talk then. This discussion should have happened on a weekly basis. I guarantee *kuch hua nahi hai* (nothing has happened). Why?
**TB:** No, we...
**AS:** (Sarcastic) Very good job. So the person who is directing you to make content has no f***ing interest in understanding whether that is working or not?

**(00:45 - 02:00)**
**TB:** He comes to us and asks whether the generator... means the portal is appropriately going through or not...
**AS:** Your answer is what? Yes? No?
**TB:** No, whenever we *were* facing the challenges we emailed and also informed him that yes, that challenge we are facing...
**AS:** How is it different from you informing me then? No difference, no?
**TB:** (Silence)

**(02:00 - 03:15)**
**AS:** So the content that is being generated, Tamalika... is this all out of the MedWikis?
**TB:** Yes sir, generated...
**AS:** So today, the 1600, 1700 that we generated are all out of the MedWiki videos that have been done?
**TB:** Not only videos sir, curated... also we have done. Means from the generator module.
**AS:** How many of these are from curated and how many of these are from MedWikis?
**TB:** Sir, I have not separated those numbers so I have to...
**AS:** Yeah, but I want to know.
**TB:** Yes.
**AS:** Isn't that the whole point of having a review? Because the curated will have less concrete information available with you because there is no transcript to refer to. How are you tracking curated versus [Medwiki]?
**TB:** Sir, I have assigned one person, that is Udipto, to generate the content from the CME portions. And the rest of us are using the generator module to craft the MedWiki on a particular topic.
**AS:** Has that been reviewed by you? This plan of action? Of having one person generate this?
**UB:** No, no sir.
**AS:** Do you want to review these things with her? Do you see any trouble with this approach so far?

**(03:15 - 04:20)**
**UB:** Trouble as in sir... from one topic I am generating 7-8... I mean MedWikis. Whereas... I wanted like from one topic, four... max to max five topics, so as to get more. That was the only thing.
**AS:** So the question was, do you see a challenge with the approach of giving one person the responsibility of all transcript-generated content versus how many people?
**TB:** Three people we are doing curated.
**AS:** Three people doing curated. How many did the three people publish versus how many did Udipto Bar publish?
**TB:** Udipto Bar published... here it is 384.
**AS:** Out of 2200-ish?
**TB:** Yes sir.
**AS:** So the rest 1900 are all curated, huh?
**TB:** Yes.

**(04:20 - 05:40)**
**AS:** And on what basis are we curating that? *Matlab* (Meaning), where is the topic coming from? How is the pathology selected?
**TB:** Topics Udipto has given the list of topics. And we are doing on that basis.
**AS:** You get a list from Udipto, you put it in one by one and generate the titles? And whichever one you liked...
**TB:** (Interrupts) Not whichever one we liked. Whichever ones we don't have much written about.
**AS:** How do you check if much is written or not?
**TB:** Sir, by going to the portal and checking that topic.
**AS:** So whatever topic is generated, you take that and search it?
**TB:** *Haan, matlab man lijiye sir* (Yes, suppose sir), Diabetic Kidney Disease. If the generator module is giving us 7 variants, then we search Diabetic Kidney Disease on the portal to see what transcripts... suppose in '24 or '23 it is written. If it's a bit outdated, we generate new. Like this, looking at the topic, we search what is written and not written.
**UB:** (Interjects about a separate report due regarding Sun Pharma being urgent).
**AS:** (Dismisses the interruption) *Kal khatam hone ka baat tha* (It was supposed to be finished yesterday).

**(05:40 - 07:00)**
**AS:** So, am I right in assuming that the bulk of the time you spend is in searching whether you have duplications or not?
**TB:** Not that... means...
**AS:** In the process, the most time consuming element is going and searching in the portal, *na*?
**TB:** Yes, yes.
**AS:** *Theek hai*, understood. We are all driving a point home, okay? Not all feedback is for you. Or for him. Or for me. We will each take what we can from it. The objective of doing this was that we will do 100% coverage of all our MedWikis/CMEs. It doesn't look like it is happening. This sheet has two months of data?
**TB:** Yes sir, last October... yeah October to...
**AS:** I believe in the last one and a half months I would have done 500 CMEs.
**TB:** CMEs exact number...
**AS:** 500. I do almost 350-400 CMEs a month. Even if client says remove this, you are right that number is incorrect. I think internal *mein apne 110-120 kiya hoga* (internally we must have done 110-120).

**(07:00 - 08:30)**
**AS:** So you are saying out of 150 CMEs, only 400 pieces of content... is this published or created?
**TB:** No sir, already published it is.
**AS:** So how much is created?
**TB:** They are working now...
**AS:** No, you are not understanding my question. So this 2286, is this the total number produced?
**TB:** Yes, total number produced.
**AS:** And 384 is the total number produced [by Udipto], not published?
**TB:** Out of these, how many published...
**AS:** (Interrupts) No that's okay, that's later. So 2286 is the total number of produced. So 150 odd CMEs produced 400 pieces of content. I don't think that number adds up. Which means you guys are either skipping CMEs?
**TB:** Sir one thing happens. Suppose we have drafted content. And the CME title matches. When Udipto sees that content has already been made on this, he skips it.
**AS:** How do we know that the content is not different? Maybe the approach towards Postpartum Hemorrhage has changed this year compared to last year. How do you check for that difference in opinion?
**TB:** No sir, there is no way.
**AS:** You don't check for that.

**(08:30 - 11:30)**
**TB:** Because we just check the duplicates whether it is there or not in recent times. Whenever we draft those, we try to put some new information from new journals. So on that basis of thought, we think maybe this topic can be skipped.
**AS:** I don't understand how Udipto Bar is taking that decision. I don't understand how *one* person can do multi-specialty content links. And not just chota-mota (small) multi-specialty. *All* specialties.
**TB:** Sir all of us are writing across specialties.
**AS:** (Points out the previous team structure had dedicated people for specialties like Neuro, Cardiac, etc). Now you gave one person Gyne, Euro, and Andro...
**UB:** Yeah that will be better. Because then they will be seeing that only. That makes a lot of sense.
**AS:** I mean they need to follow what the journals are talking about rather than knowing everything. They can't f***ing know everything. Because it will be all over the place. And if you are increasing volume of creation, you can't have the mind running like that.

**(11:30 - 14:00)**
**AS:** I don't understand how we ended up publishing only 6-8 pieces in Endo?
**TB:** Sir actually... if we can see that in General Medicine specialty also there might be some Endocrinology. There is an overlap.
**AS:** Are you multi-tagging or primary tagging?
**TB:** No, no, multi-tagging we do.
**AS:** So the count you showed me is not multiple tagged? It is primary tagged.
**TB:** Primary tagged.
**AS:** Okay. So you spend the vast majority of your time after this generation is done in checking whether something is close or not? And whether something is relevant or necessary? How do you check for necessity?
**TB:** Suppose it is written for treatment considerations. In that, pathophysiology, causes, and risk factors... if in brief it is okay. But if it is elaborate...
**AS:** (Interrupting) But in automated content you will only know *after* you generated it. Before generation how do you know?
**TB:** No sir... (Pause).
**AS:** By the way, I forgot to tell you something. My job is to find errors. You realize that right? My role in your lives is to be the bad guy. To be the guy who shows you a mirror and says you are an idiot. You are an intelligent person 95% of the time, that is fine. But my job is to focus on the 5%. I wanted to clarify this to you Tamalika. I know you feel this... and Udipto *to bechara mere se pareshan hai hi* (Udipto is anyway troubled by me)... that whenever sir opens his mouth he gives abuse.

**(14:00 - 15:30)**
**AS:** Our job will be to focus on content which is engaging people, not on engaging *with* people on the platform. Somebody else will do that. So basically, please don't be disheartened by my harshness. You are probably at the frontier of medical innovation when it comes to content generation. I don't think anybody is generating and publishing content with the balls that we have right now.
*(AS explains that the fact they verify and correct is critical).*
**AS:** No matter who writes it, it cannot be incorrect. That please don't for a moment think we underestimate that role.

**(15:30 - End of relevant business discussion, moving to screen review)**
**AS:** Let's go back to your issues sheet please.
**TB:** (Shows screen) Absence of in-text citations.
**AS:** Okay I understand. Non-compliance with AMA... okay. Improper structural placement.
**TB:** Non-sequential reference numbering.
**AS:** Tell me how old this sample is. It looks like there is one sample which failed everything.
**TB:** No sir, for four samples...
**AS:** It looks like there are certain ones which just refuse to listen to you.
**AS:** Arnab (addressing Arnab on call), basically we need to pass these into second-step processing. So your feedback loop... the HTML generation part is something...
**AS:** We need to give them iteration capabilities. So that they can read it, review it, and the LLM takes their comment and re-does it. Actually, without comment, we shouldn't allow regeneration. Because that will be abuse.
**AS:** So what I am saying, maybe we should take the formatting portion out completely into an independent call. So that consistency adds up.
**TB:** This happens most of the time... Incorrect URLs. We click the link and it opens a different article.
**AS:** And incorrect dosages?
**TB:** Yes. Sometimes they mistake the dose calculations. They are incorrect based on recent guidelines.
**AS:** Okay.
**AS:** The prompt that is being used is super generic in nature. You are not seeing these fine items coming in.
**TB:** Sir, if we can give comments like this, can the generator module provide better output?
**AS:** Yes. We can create a guidance.
**AS:** We should aim to have a second round of changes happening in this over the next two weeks.
**AS:** And regarding specialty division... see who does a better job of what specialty and give them that. Club specialties together. Cardio-Diabetic-CTVS in one. Gyne-Euro-Nephro in one. It has to be a combination of bulk therapy plus super specialization.
**AS:** Just because you produce more content doesn't mean you are getting *better* content produced.

*(End of Transcript)*

***

### **Minutes of Meeting (MoM)**

**Date:** November 18, 2025
**Meeting:** Automated Content Output and Reference Review
**Attendees:** Arnab Saha (AS), Tamalika Basak (TB), Udipto Bar (UB), Arnab (Remote/Tech).

**Agenda:**
Review the challenges faced in the automated content generation process, assess the quality of outputs, and discuss workflow optimization.

**Key Discussion Points:**

**1. Quality Control & Content Issues:**
*   **Formatting & Citations:** The team reported frequent issues with the automated content, including:
    *   Absence of in-text citations.
    *   Non-compliance with AMA citation styles.
    *   Non-sequential reference numbering.
    *   Structural placement issues (e.g., References appearing in the Conclusion section).
*   **Hallucinations:** The Generative AI frequently produces incorrect URLs (opening irrelevant articles) and incorrect Author details.
*   **Medical Accuracy:** There are instances of incorrect dosage calculations or contraindications that contradict recent medical guidelines (both European and American).

**2. Workflow Efficiency & Volume:**
*   **Production Ratio:** Approximately 2286 pieces of content were generated, but only ~384 (from the curated batch) and ~1059 (total published) were finalized.
*   **Duplication Check Bottleneck:** A significant amount of time (approx. 25-45 minutes per article) is spent manually searching the portal to ensure the topic hasn't been covered previously.
*   **AS Feedback:** AS strongly criticized this workflow, stating that manual duplication checking is an inefficient use of time. The process needs to move away from manual "ticking" to a control-center approach.

**3. Specialty Allocation:**
*   Currently, writers are handling topics across all specialties randomly based on lists.
*   **Decision:** This approach is causing a lack of depth. Writers should be assigned specific "clusters" of specialties (e.g., Cardio/Diabetic/CTVS together; Gyne/Uro/Nephro together) to build subject matter expertise and follow specific journals.

**4. Prompt Engineering & Automation:**
*   The current prompts being used are too generic, leading to inconsistent formatting.
*   **Solution:** The generation process needs a "Second Step Processing" or an iteration loop. Instead of the user fixing formatting manually, they should provide comments to the LLM to regenerate and fix the errors.
*   Formatting checks (HTML, structure) should potentially be separated into an independent automated call to ensure consistency.

**Action Items:**

| Action Item | Responsibility | Deadline |
| :--- | :--- | :--- |
| **Implement Iteration Loop:** Enable a feature where the team can provide comments on generated content, and the LLM regenerates the output based on that feedback (preventing manual editing). | Tech Team (Arnab) | Next 2 Weeks |
| **Update Prompt Strategy:** Refine prompts to be less generic and include specific instructions regarding formatting (tables, bullets) and citations. | AS / Tech Team | Immediate |
| **Restructure Specialty Assignment:** Re-organize the team so that individuals handle specific clusters of medical specialties rather than general topics. | TB / AS | Immediate |
| **Review SOP:** Update the Standard Operating Procedure (SOP) to reflect the new workflow (focus on iteration rather than manual fixing). | TB | Before AS returns (28th) |


**Closing Note:**
AS emphasized that while his feedback is harsh, the team is doing pioneering work in medical content generation. The goal is to maximize efficiency and ensure 100% coverage of CMEs, which is currently lagging.
